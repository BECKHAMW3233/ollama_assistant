# Ollama Assistant Web UI

A web-based user interface for interacting with Ollama AI models with NVIDIA RTX 4080 GPU acceleration.

## Features

- Simple chat interface
- Support for multiple models including CodeLlama, Phi3, Dolphin-Mistral, and more
- File upload capabilities
- Parameter customization (temperature, top-p, etc.)
- Dark mode
- GPU acceleration with NVIDIA RTX 4080
- External access via ngrok

## Requirements

- Node.js (v16+)
- Ollama (latest version)
- NVIDIA GPU (tested with RTX 4080)
- WSL2 on Windows 11

## Installation

1. Clone this repository:
```bash
git clone https://github.com/YOUR_USERNAME/ollama-assistant.git
cd ollama-assistant


